{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NLeZZNLIOBM-"
      },
      "source": [
        "# Preprocess images\n",
        "\n",
        "To make model training more efficient and facilitate our many experiments, we perform some preprocessing on the images so that this does not need to be repeated for each experiment. The preprocessed versions are saved as .npy files.\n",
        "\n",
        "For the detector we preprocess to obtain three types of input:\n",
        "* 256x256 partitions of Y-component\n",
        "* 256x256 partitions of DCT coefficients\n",
        "* 64x120 DCT histogram features\n",
        "\n",
        "For the restorer we only preprocess to obtain 256x256 RGB partitions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "teBNhnbzS8PN"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "We obtain DCT histogram features using a method developed by Barni et al., which can be read in their paper: https://arxiv.org/abs/1708.00930\n",
        "\n",
        "We use the implementation of Barni's method as developed by Park et al., which is found here: https://github.com/plok5308/DJPEG/blob/master/DJPEG_net.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE6BnxvYTXH0"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdhmxAiczdus",
        "outputId": "d9036ac4-b0c0-459d-b3b7-1fb579973449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from PIL import JpegImagePlugin\n",
        "from PIL import Image\n",
        "import scipy.fftpack\n",
        "import numpy as np\n",
        "from numpy import r_\n",
        "from numpy import pi\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import math\n",
        "from multiprocessing.dummy import Pool\n",
        "import threading\n",
        "import sys\n",
        "from itertools import repeat\n",
        "from google.colab import drive\n",
        "\n",
        "# Connect google drive and set default path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# IMPORTANT: Change this to your own path, ending with \"dataset/\"\n",
        "PATH = '/content/drive/MyDrive/dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo1unc-DUcg3"
      },
      "source": [
        "## Detector\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqXzy2opXwLP"
      },
      "source": [
        "### Y-component pixel partitioning\n",
        "\n",
        "We partition the images in the dataset into blocks of 256x256 of the Y-component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24W8Mvibzduw"
      },
      "outputs": [],
      "source": [
        "SQUARE_SIZE = 256\n",
        "\n",
        "\n",
        "def get_image_squares(x, compress=\"s\", SQF=50, DQF=\"\"):\n",
        "    '''Convert x^th image in dataset into blocks of 256x256 of the Y channel in \n",
        "    YCbCr'''\n",
        "\n",
        "    imgs = []\n",
        "\n",
        "    # Download image\n",
        "    try:\n",
        "        img = np.array(Image.open(\n",
        "            PATH + f\"raise/{compress}jpeg{SQF}{DQF}/image_{x}.jpg\"))\n",
        "    except:\n",
        "        print(f\"Can't download {x}\")\n",
        "\n",
        "    # Get Y-component only\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "    img = img[:, :, :1]\n",
        "\n",
        "    #  Partition the image\n",
        "    for i in range(0, len(img)-SQUARE_SIZE, SQUARE_SIZE):\n",
        "        for j in range(0, len(img[i])-SQUARE_SIZE, SQUARE_SIZE):\n",
        "            imgs.append((img[i:i+SQUARE_SIZE, j:j+SQUARE_SIZE]))\n",
        "\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt8eSojZXcei"
      },
      "source": [
        "Preprocess the images and save as .npy files. Store partitions from 200 images in one file (to handle RAM constraints)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZuHVXeqNa0i"
      },
      "outputs": [],
      "source": [
        "# Preprocess and save all the images\n",
        "for top in range(0, 200, 1000):\n",
        "    for cat in [\"no\", \"single\", \"double\"]:\n",
        "        for QF in [10, 30, 50, 70, 90]:\n",
        "\n",
        "            # Settings\n",
        "            if cat == \"single\":\n",
        "                SQF = QF\n",
        "                DQF = \"\"\n",
        "            elif cat == \"double\":\n",
        "                SQF = 50\n",
        "                DQF = QF\n",
        "            else:  # no\n",
        "                if QF > 10:\n",
        "                    continue  #  Only process no compression once\n",
        "                SQF = \"\"\n",
        "                DQF = \"\"\n",
        "\n",
        "            print(f\"Processing {top}-{top+200} {cat} compression with QF=({SQF},{DQF})\")\n",
        "\n",
        "            # Download and partition images with a threadpool for efficiency\n",
        "            with Pool(threading.active_count()) as p:\n",
        "                res = p.starmap(get_image_squares, zip(\n",
        "                    range(top, top+200), repeat(cat[0]), repeat(SQF), repeat(DQF)))\n",
        "\n",
        "            #  Flatten array of images\n",
        "            imgs = np.array(sum(res, []))\n",
        "            del res\n",
        "\n",
        "            #  Save blocks\n",
        "            np.save(\n",
        "                PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockimg{top+200}.npy\", imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2piavZUqhEKf"
      },
      "source": [
        "### DCT coefficients of partitions\n",
        "\n",
        "We also store a version of the 256x256 blocks in the DCT domain, using the DCT2 algorithm on each of the 256x256 Y-component blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De3QDAR722rQ"
      },
      "outputs": [],
      "source": [
        "def dct2(a):\n",
        "    '''Returns the DCT2 of image block'''\n",
        "    return scipy.fftpack.dct(\n",
        "        scipy.fftpack.dct(a, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
        "\n",
        "\n",
        "def idct2(a):\n",
        "    '''Returns the inverse DCT2 of image block'''\n",
        "    return scipy.fftpack.idct(\n",
        "        scipy.fftpack.idct(a, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
        "\n",
        "\n",
        "def dct8x8(im):\n",
        "    '''Computes DCT2 for each 8x8 block of the image and returns the resulting \n",
        "    coefficients'''\n",
        "\n",
        "    #  Get Y-component only\n",
        "    im = im[:, :, 0]\n",
        "    imsize = im.shape\n",
        "    dct = np.zeros(imsize)\n",
        "\n",
        "    # Do 8x8 DCT on image (in-place)\n",
        "    for i in r_[:imsize[0]:8]:\n",
        "        for j in r_[:imsize[1]:8]:\n",
        "            dct[i:(i+8), j:(j+8)] = dct2(im[i:(i+8), j:(j+8)])\n",
        "\n",
        "    return dct[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKBRYyxki5rs"
      },
      "source": [
        "Preprocess the images and save as .npy files. Store partitions from 200 images in one file (to handle RAM constraints)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwToW7jHkmC4"
      },
      "outputs": [],
      "source": [
        "# Preprocess and save all the images\n",
        "for top in [\"200\", \"400\", \"600\", \"800\", \"1000\"]:\n",
        "    for cat in [\"no\", \"single\", \"double\"]:\n",
        "        for QF in [10, 30, 50, 70, 90]:\n",
        "\n",
        "            # Settings\n",
        "            if cat == \"single\":\n",
        "                SQF = QF\n",
        "                DQF = \"\"\n",
        "            elif cat == \"double\":\n",
        "                SQF = 50\n",
        "                DQF = QF\n",
        "            else:  # no\n",
        "                if QF > 10:\n",
        "                    continue  #  Only process no compression once\n",
        "                SQF = \"\"\n",
        "                DQF = \"\"\n",
        "\n",
        "            print(f\"Processing {top} {cat} compression with QF=({SQF},{DQF})\")\n",
        "\n",
        "            # Load image partitions\n",
        "            imgs = np.load(\n",
        "                PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockimg{top}.npy\")\n",
        "\n",
        "            #  Process each image partition one-by-one\n",
        "            for i in range(len(imgs)):\n",
        "                imgs[i] = dct8x8(imgs[i])\n",
        "\n",
        "            np.save(\n",
        "                PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockdct{top}.npy\", imgs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "62IxlEFyhHls"
      },
      "source": [
        "### DCT histogram features of partitions\n",
        "\n",
        "We process each of the 256x256 Y-component blocks, converting it to 64x120 DCT histogram features, as proposed by Barni et al., and as implemented by Park et al."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fbZ8T9RZzduy"
      },
      "outputs": [],
      "source": [
        "# Parts taken from https://github.com/plok5308/DJPEG/blob/master/DJPEG_net.py\n",
        "# Calculates the DCT histogram features using convolutional layers\n",
        "\n",
        "def cal_scale(p, q):\n",
        "    if p == 0:\n",
        "        ap = 1/(math.sqrt(8))\n",
        "    else:\n",
        "        ap = math.sqrt(0.25)\n",
        "    if q == 0:\n",
        "        aq = 1/(math.sqrt(8))\n",
        "    else:\n",
        "        aq = math.sqrt(0.25)\n",
        "\n",
        "    return ap, aq\n",
        "\n",
        "\n",
        "def cal_basis(p, q):\n",
        "    basis = np.zeros((8, 8))\n",
        "    ap, aq = cal_scale(p, q)\n",
        "    for m in range(0, 8):\n",
        "        for n in range(0, 8):\n",
        "            basis[m, n] = ap*aq * \\\n",
        "                math.cos(math.pi*(2*m+1)*p/16)*math.cos(math.pi*(2*n+1)*q/16)\n",
        "\n",
        "    return basis\n",
        "\n",
        "\n",
        "def load_DCT_basis_64():\n",
        "    basis_64 = np.zeros((8, 8, 64))\n",
        "    idx = 0\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            basis_64[:, :, idx] = cal_basis(i, j)\n",
        "            idx = idx + 1\n",
        "    return basis_64\n",
        "\n",
        "\n",
        "def conv2d_8(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 8, 8, 1], padding=\"SAME\")\n",
        "\n",
        "\n",
        "DCT_basis_64 = load_DCT_basis_64()\n",
        "np_basis = np.zeros((8, 8, 1, 64))\n",
        "for i in range(64):\n",
        "    np_basis[:, :, 0, i] = DCT_basis_64[:, :, i]\n",
        "\n",
        "w_basis = tf.constant(np_basis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKC2uShcQif"
      },
      "source": [
        "Process image partitions using Barni et al. method. We process only 15000 at a time due to RAM constraints. Each 15000 are stored in a separate files, which we later combine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5wiYibfCSKQ"
      },
      "outputs": [],
      "source": [
        "# Preprocess and save all the images\n",
        "for top in [\"200\", \"400\", \"600\", \"800\", \"1000\"]:\n",
        "    for cat in [\"no\", \"single\", \"double\"]:\n",
        "        for QF in [10, 30, 50, 70, 90]:\n",
        "\n",
        "            # Settings\n",
        "            if cat == \"single\":\n",
        "                SQF = QF\n",
        "                DQF = \"\"\n",
        "            elif cat == \"double\":\n",
        "                SQF = 50\n",
        "                DQF = QF\n",
        "            else:  # no\n",
        "                if QF > 10:\n",
        "                    continue  #  Only process no compression once\n",
        "                SQF = \"\"\n",
        "                DQF = \"\"\n",
        "\n",
        "            print(f\"Processing {top} {cat} compression with QF=({SQF},{DQF})\")\n",
        "\n",
        "            # Load image partitions\n",
        "            imgs = np.load(\n",
        "                PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockimg{top}.npy\")\n",
        "\n",
        "            # Process image partitions using Barni et al. method\n",
        "            # We process only 15000 at a time due to RAM constraints\n",
        "            for i in range(0, 45000, 15000):\n",
        "                x2 = conv2d_8(imgs[i:i+15000], w_basis)  # Nx32x32x64\n",
        "\n",
        "                gamma = 1e+06\n",
        "                for b in range(-60, 61):\n",
        "                    x3 = tf.divide(tf.reduce_sum(\n",
        "                        tf.sigmoid(tf.scalar_mul(gamma, tf.subtract(x2, b))), [1, 2]), 1024)\n",
        "                    x3 = tf.reshape(x3, [-1, 1, 64])\n",
        "\n",
        "                    if b == -60:\n",
        "                        x4 = x3\n",
        "                    else:\n",
        "                        x4 = tf.concat([x4, x3], 1)\n",
        "\n",
        "                x5 = x4[:, 0:120, :] - x4[:, 1:121, :]\n",
        "                x6 = tf.reshape(x5, [-1, 120, 64, 1])  # Input for CNN\n",
        "\n",
        "                np.save(\n",
        "                    PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockcnn{top}_{i//15000 + 1}.npy\", x6.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZmdnV6PcUzU"
      },
      "source": [
        "Combine the preprocessed files. Store partitions from 200 images in one file (to handle RAM constraints)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae9TKw-rFElG"
      },
      "outputs": [],
      "source": [
        "# Combine files\n",
        "for top in [\"200\", \"400\", \"600\", \"800\", \"1000\"]:\n",
        "    for cat in [\"no\", \"single\", \"double\"]:\n",
        "        for QF in [10, 30, 50, 70, 90]:\n",
        "\n",
        "            # Settings\n",
        "            if cat == \"single\":\n",
        "                SQF = QF\n",
        "                DQF = \"\"\n",
        "            elif cat == \"double\":\n",
        "                SQF = 50\n",
        "                DQF = QF\n",
        "            else:  # no\n",
        "                if QF > 10:\n",
        "                    continue  #  Only process no compression once\n",
        "                SQF = \"\"\n",
        "                DQF = \"\"\n",
        "\n",
        "            #  Combine preprocessed files\n",
        "            try:\n",
        "                imgs = np.load(\n",
        "                    PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockcnn{top}_1.npy\")\n",
        "                for i in range(2, 4):\n",
        "                    imgs = np.concatenate((imgs, np.load(\n",
        "                        PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockcnn{top}_{i}.npy\")))\n",
        "                np.save(\n",
        "                    PATH + f\"detector_npy/{cat[0]}jpeg{SQF}{DQF}/{cat}blockcnn{top}.npy\", imgs)\n",
        "            except:\n",
        "                print(f\"Could not combine {top}, {cat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9dc9TDqV6lZ"
      },
      "source": [
        "## Restorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dslzPHzuf1-E"
      },
      "source": [
        "### RGB pixel partitioning\n",
        "\n",
        "As opposed to the detector, we use the coloured image (RGB) rather than a grayscale version. We also only partition once per image, due to RAM constraints in training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M8EkNGRTV9At"
      },
      "outputs": [],
      "source": [
        "SQUARE_SIZE = 256\n",
        "\n",
        "\n",
        "def get_rgb_image_square(x, compress=\"s\", SQF=50, DQF=\"\"):\n",
        "    '''Convert x^th image in dataset into blocks of 256x256, including all RGB\n",
        "    channels'''\n",
        "\n",
        "    #  Download image\n",
        "    try:\n",
        "        img = np.array(Image.open(\n",
        "            PATH + f\"raise/{compress}jpeg{SQF}{DQF}/image_{x}.jpg\"))\n",
        "    except:\n",
        "        print(f\"Can't download {x}\")\n",
        "\n",
        "    #  Partition the image, ensuring to make 8x8 blocks aligned\n",
        "    start_x = next_n((len(img) // 2) - (SQUARE_SIZE // 2), 8)\n",
        "    start_y = next_n((len(img[0]) // 2) - (SQUARE_SIZE // 2), 8)\n",
        "\n",
        "    imgs = [img[\n",
        "        start_x: start_x+SQUARE_SIZE,\n",
        "        start_y: start_y+SQUARE_SIZE\n",
        "    ]]\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def next_n(num, n):\n",
        "    '''Returns num rounded to the next multiple of n'''\n",
        "    return n * ((num-1) // n) + n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpGI8VeJi-wB"
      },
      "source": [
        "Preprocess the images and save as .npy files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2oylIeQV_YM"
      },
      "outputs": [],
      "source": [
        "# Preprocess and save all the images\n",
        "for cat in [\"no\", \"single\", \"double\"]:\n",
        "    for QF in [10, 30, 50, 70]:\n",
        "\n",
        "        # Settings\n",
        "        if cat == \"single\":\n",
        "            SQF = QF\n",
        "            DQF = \"\"\n",
        "        elif cat == \"double\":\n",
        "            SQF = 50\n",
        "            DQF = QF\n",
        "        else:  # no\n",
        "            if QF > 10:\n",
        "                continue  #  Only process no compression once\n",
        "            SQF = \"\"\n",
        "            DQF = \"\"\n",
        "\n",
        "        imgs = None\n",
        "\n",
        "        #  Download and partition images with a threadpool for efficiency\n",
        "        #  Process 200 at a time due to RAM constraints\n",
        "        for i in range(0, 1000, 200):\n",
        "            with Pool(threading.active_count()) as p:\n",
        "                t = p.starmap(get_rgb_image_square, zip(\n",
        "                    range(i, i+200), repeat(cat[0]), repeat(SQF), repeat(DQF)))\n",
        "                t = sum(t, [])\n",
        "            if imgs is not None:\n",
        "                imgs = np.concatenate((imgs, t))\n",
        "            else:\n",
        "                imgs = t\n",
        "\n",
        "        #  Save all blocks\n",
        "        np.save(PATH + f\"restorer_npy/{cat[0]}jpeg{SQF}{DQF}lite.npy\", imgs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 16:55:46) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
